{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dervla Gargan - 22346279\n",
    "Mark Langtry - 22340475\n",
    "Amy McMahon - 22346619\n",
    "\n",
    "Code executed without errors :)\n",
    "\n",
    "**Links used**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.44448957,  0.        ], dtype=float32), {})"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('MountainCar-v0', render_mode='human')\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = env.observation_space\n",
    "actions = env.action_space\n",
    "EPSILON = 1\n",
    "NUM_ACTIONS = actions.n\n",
    "LEARNING_RATE = 0.001  # Adjust as needed\n",
    "DISCOUNT_FACTOR = 0.99  # Adjust as needed\n",
    "NUM_EPISODES = 1000\n",
    "replay_buffer_size = 10000  # Adjust as needed\n",
    "batch_size = 32  # Adjust as needed\n",
    "update_target_network_freq = 100  # Adjust as needed\n",
    "rewards_per_episode = []\n",
    "EPSILON = 1\n",
    "EPSILON_DECAY = 1 / NUM_EPISODES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "input_shape = [4]\n",
    "n_outputs = 2\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(24, activation='relu', input_shape=state_shape),\n",
    "    tf.keras.layers.Dense(48, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_ACTIONS, activation='linear')\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=LEARNING_RATE), loss='mse')\n",
    "\n",
    "target_model = tf.keras.models.clone_model(model)\n",
    "target_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmenting velocity and position "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = np.linspace(space.low[0], space.high[0], 20)\n",
    "velocity = np.linspace(space.low[1], space.high[1], 20)\n",
    "\n",
    "replay_buffer = deque(maxlen=replay_buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(position, velocity, epsilon):\n",
    "    if np.random.random() < epsilon:\n",
    "        return np.random.randint(NUM_ACTIONS)\n",
    "    else:\n",
    "        q_values = model.predict(np.array([[position, velocity]]))[0]\n",
    "        return np.argmax(q_values)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(state, epsilon=0):\n",
    "    print(state)\n",
    "    if np.random.rand() >= epsilon:\n",
    "        return np.random.randint(n_outputs)\n",
    "    else:\n",
    "        state_array = state[0]\n",
    "        Q_values = model.predict(state_array[np.newaxis], verbose=0)[0]\n",
    "\n",
    "        return Q_values.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_step(env, state, epsilon):\n",
    "    action = epsilon_greedy_policy(state, epsilon)\n",
    "    next_state, reward, done, info, _ = env.step(action)\n",
    "    replay_buffer.append((state, action, reward, next_state, done))\n",
    "    return next_state, reward, done, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset(seed=42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "rewards = []\n",
    "best_score = 0\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = deque(maxlen=400)\n",
    "\n",
    "def sample_experiences(batch_size):\n",
    "    indices = np.random.randint(len(replay_buffer), size=batch_size)\n",
    "    batch = [replay_buffer[index] for index in indices]\n",
    "    return [\n",
    "        np.array([experience[field_index] for experience in batch])\n",
    "        for field_index in range(5)\n",
    "    ]  # [states, actions, rewards, next_states, dones, truncateds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize = tf.keras.optimizers.Nadam(learning_rate=1e-2)\n",
    "lossFunc = tf.keras.losses.mean_squared_error\n",
    "\n",
    "def training(batch_size):\n",
    "    experiences = sample_experiences(batch_size)\n",
    "    states, actions, rewards, next_states, dones = experiences\n",
    "    next_Q_values = model.predict(next_states, verbose=0)\n",
    "    min_next_Q_values = next_Q_values.min(axis=1)\n",
    "    runs = 1.0 - (dones)\n",
    "    target_Q_values = rewards + runs * discount_factor * min_next_Q_values\n",
    "    target_Q_values = target_Q_values.reshape(-1, 1)\n",
    "    mask = tf.one_hot(actions, n_outputs)\n",
    "    with tf.GradientTape() as tape:\n",
    "        all_Q_values = model(states)\n",
    "        Q_values = tf.reduce_sum(all_Q_values * mask, axis=1, keepdims=True)\n",
    "        loss = tf.reduce_mean(loss_fn(target_Q_values, Q_values))\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-0.5122243,  0.       ], dtype=float32), {})\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001FA41104E00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001FA41104E00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.123096e-01 -8.529192e-05]\n",
      "[-0.51347953 -0.00116994]\n",
      "[-0.5157254  -0.00224583]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sequential_8/dense_24/MatMul defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n\n  File \"C:\\Users\\admcm\\AppData\\Local\\Temp\\ipykernel_35456\\3642026326.py\", line 5, in <module>\n\n  File \"C:\\Users\\admcm\\AppData\\Local\\Temp\\ipykernel_35456\\518707595.py\", line 2, in play_one_step\n\n  File \"C:\\Users\\admcm\\AppData\\Local\\Temp\\ipykernel_35456\\309527322.py\", line 7, in epsilon_greedy_policy\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2655, in predict\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 590, in __call__\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\sequential.py\", line 398, in call\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\functional.py\", line 515, in call\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\functional.py\", line 672, in _run_internal_graph\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py\", line 241, in call\n\nIn[0] ndims must be >= 2: 1\n\t [[{{node sequential_8/dense_24/MatMul}}]] [Op:__inference_predict_function_1910]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[111], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m200\u001b[39m):\n\u001b[0;32m      4\u001b[0m     epsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m----> 5\u001b[0m     obs, reward, done, info  \u001b[38;5;241m=\u001b[39m \u001b[43mplay_one_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[106], line 2\u001b[0m, in \u001b[0;36mplay_one_step\u001b[1;34m(env, state, epsilon)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplay_one_step\u001b[39m(env, state, epsilon):\n\u001b[1;32m----> 2\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mepsilon_greedy_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     next_state, reward, done, info, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m      4\u001b[0m     replay_buffer\u001b[38;5;241m.\u001b[39mappend((state, action, reward, next_state, done))\n",
      "Cell \u001b[1;32mIn[105], line 7\u001b[0m, in \u001b[0;36mepsilon_greedy_policy\u001b[1;34m(state, epsilon)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m     state_array \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 7\u001b[0m     Q_values \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_array\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Q_values\u001b[38;5;241m.\u001b[39margmax()\n",
      "File \u001b[1;32mc:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sequential_8/dense_24/MatMul defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n\n  File \"C:\\Users\\admcm\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n\n  File \"C:\\Users\\admcm\\AppData\\Local\\Temp\\ipykernel_35456\\3642026326.py\", line 5, in <module>\n\n  File \"C:\\Users\\admcm\\AppData\\Local\\Temp\\ipykernel_35456\\518707595.py\", line 2, in play_one_step\n\n  File \"C:\\Users\\admcm\\AppData\\Local\\Temp\\ipykernel_35456\\309527322.py\", line 7, in epsilon_greedy_policy\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2655, in predict\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 590, in __call__\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\sequential.py\", line 398, in call\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\functional.py\", line 515, in call\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\functional.py\", line 672, in _run_internal_graph\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py\", line 241, in call\n\nIn[0] ndims must be >= 2: 1\n\t [[{{node sequential_8/dense_24/MatMul}}]] [Op:__inference_predict_function_1910]"
     ]
    }
   ],
   "source": [
    "for episode in range(300):\n",
    "    obs = env.reset()\n",
    "    for step in range(200):\n",
    "        epsilon = 0.5\n",
    "        obs, reward, done, info  = play_one_step(env,obs, epsilon)\n",
    "        if done:\n",
    "            break\n",
    "    print(f\"\\rEpisode: {episode + 1}, Steps: {step + 1}, eps: {epsilon:.3f}\",\n",
    "          end=\"\")\n",
    "    rewards.append(step)\n",
    "    if step >= best_score:\n",
    "        best_weights = model.get_weights()\n",
    "        best_score = step\n",
    "\n",
    "    if episode > 50:\n",
    "        training_step(batch_size)\n",
    "\n",
    "model.set_weights(best_weights)\n",
    "\n",
    "# for episode in range(NUM_EPISODES):\n",
    "#     env.render()\n",
    "#     train()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(EPSILON, EPSILON_DECAY):\n",
    "#     state = env.reset()[0]\n",
    "#     state_position = np.digitize(state[0], position)\n",
    "#     state_velocity = np.digitize(state[1], velocity)\n",
    "\n",
    "#     goal = False\n",
    "\n",
    "#     rewards = 0\n",
    "\n",
    "#     while not goal and rewards > -1000:\n",
    "#         action = select_action(state)\n",
    "#         next_state, reward, goal, _, _ = env.step(action)\n",
    "#         next_state_position = np.digitize(next_state[0], position)\n",
    "#         next_state_velocity = np.digitize(next_state[1], velocity)\n",
    "#         max_q_value_next_state = np.max(q_values[next_state_position][next_state_velocity])\n",
    "#         q_values[state_position][state_velocity][action] += LEARNING_RATE * (reward + DISCOUNT_FACTOR * \n",
    "#                                 max_q_value_next_state - q_values[state_position][state_velocity][action])\n",
    "#         state_position = next_state_position\n",
    "#         state_velocity = next_state_velocity\n",
    "\n",
    "#         rewards += reward\n",
    "\n",
    "#     rewards_per_episode.append(rewards)\n",
    "#     NEW_EPSILON = max(EPSILON - EPSILON_DECAY, 0)\n",
    "#     return NEW_EPSILON\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for episode in range(NUM_EPISODES):\n",
    "#     EPSILON = train(EPSILON, EPSILON_DECAY)\n",
    "\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_rewards = np.zeros(NUM_EPISODES)\n",
    "# for t in range(NUM_EPISODES):\n",
    "#     mean_rewards[t] = np.mean(rewards_per_episode[max(0, t-100):(t+1)])\n",
    "# plt.plot(mean_rewards)\n",
    "mean_rewards = np.zeros(NUM_EPISODES)\n",
    "for t in range(NUM_EPISODES):\n",
    "    mean_rewards[t] = np.mean(rewards_per_episode[max(0, t - 100):(t + 1)])\n",
    "plt.plot(mean_rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Mean Reward')\n",
    "plt.title('Mean Rewards per Episode')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
