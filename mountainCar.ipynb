{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dervla Gargan - 22346279\n",
    "Mark Langtry - 22340475\n",
    "Amy McMahon - 22346619\n",
    "\n",
    "Code executed without errors :)\n",
    "\n",
    "**Links used**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.51963544,  0.        ], dtype=float32), {})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('MountainCar-v0', render_mode='human')\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "space =  env.observation_space\n",
    "actions = env.action_space\n",
    "EPSILON = 1\n",
    "NUM_ACTIONS = actions.n\n",
    "LEARNING_RATE = 0.1\n",
    "DISCOUNT_FACTOR = 0.1\n",
    "NUM_EPISODES = 10\n",
    "rewards_per_episode= []\n",
    "EPSILON = 1\n",
    "EPSILON_DECAY = 2/NUM_EPISODES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_shape = env.observation_space.shape\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(24, activation='relu', input_shape=state_shape),\n",
    "        tf.keras.layers.Dense(48, activation='relu'),\n",
    "        tf.keras.layers.Dense(NUM_ACTIONS)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmenting velocity and position "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = np.linspace(space.low[0], space.high[0], 20)\n",
    "velocity = np.linspace(space.low[1], space.high[1], 20)\n",
    "\n",
    "q_values = np.zeros((len(position), len(velocity), NUM_ACTIONS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def select_action(state):\n",
    "#     if np.random.random() < EPSILON:\n",
    "#         action = np.random.randint(NUM_ACTIONS)\n",
    "#     else:\n",
    "#         action = np.argmax(model.predict(state[np.newaxis], verbose=0)[0])\n",
    "\n",
    "#     return action\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(state, epsilon=0):\n",
    "    print(state)\n",
    "    if np.random.rand() >= epsilon:\n",
    "        return np.random.randint(n_outputs)\n",
    "    else:\n",
    "        state_array = state[0]\n",
    "        Q_values = model.predict(state_array[np.newaxis], verbose=0)[0]\n",
    "\n",
    "        return Q_values.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_step(env, state, epsilon):\n",
    "    action = epsilon_greedy_policy(state, epsilon)\n",
    "    next_state, reward, done, info = env.step(action)\n",
    "    replay_buffer.append((state, action, reward, next_state, done))\n",
    "    return next_state, reward, done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset(seed=42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "rewards = []\n",
    "best_score = 0\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = deque(maxlen=400)\n",
    "\n",
    "def sample_experiences(batch_size):\n",
    "    indices = np.random.randint(len(replay_buffer), size=batch_size)\n",
    "    batch = [replay_buffer[index] for index in indices]\n",
    "    return [\n",
    "        np.array([experience[field_index] for experience in batch])\n",
    "        for field_index in range(5)\n",
    "    ]  # [states, actions, rewards, next_states, dones, truncateds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize = tf.keras.optimizers.Nadam(learning_rate=1e-2)\n",
    "lossFunc = tf.keras.losses.mean_squared_error\n",
    "\n",
    "def training(batch_size):\n",
    "    experiences = sample_experiences(batch_size)\n",
    "    states, actions, rewards, next_states, dones = experiences\n",
    "    next_Q_values = model.predict(next_states, verbose=0)\n",
    "    min_next_Q_values = next_Q_values.min(axis=1)\n",
    "    runs = 1.0 - (dones)\n",
    "    target_Q_values = rewards + runs * discount_factor * min_next_Q_values\n",
    "    target_Q_values = target_Q_values.reshape(-1, 1)\n",
    "    mask = tf.one_hot(actions, n_outputs)\n",
    "    with tf.GradientTape() as tape:\n",
    "        all_Q_values = model(states)\n",
    "        Q_values = tf.reduce_sum(all_Q_values * mask, axis=1, keepdims=True)\n",
    "        loss = tf.reduce_mean(loss_fn(target_Q_values, Q_values))\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-0.5122243,  0.       ], dtype=float32), {})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m200\u001b[39m):\n\u001b[0;32m      4\u001b[0m     epsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m----> 5\u001b[0m     obs, reward, done, info  \u001b[38;5;241m=\u001b[39m \u001b[43mplay_one_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[55], line 3\u001b[0m, in \u001b[0;36mplay_one_step\u001b[1;34m(env, state, epsilon)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplay_one_step\u001b[39m(env, state, epsilon):\n\u001b[0;32m      2\u001b[0m     action \u001b[38;5;241m=\u001b[39m epsilon_greedy_policy(state, epsilon)\n\u001b[1;32m----> 3\u001b[0m     next_state, reward, done, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m      4\u001b[0m     replay_buffer\u001b[38;5;241m.\u001b[39mappend((state, action, reward, next_state, done))\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m next_state, reward, done, info\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "for episode in range(300):\n",
    "    obs = env.reset()\n",
    "    for step in range(200):\n",
    "        epsilon = 0.5\n",
    "        obs, reward, done, info  = play_one_step(env,obs, epsilon)\n",
    "        if done:\n",
    "            break\n",
    "    print(f\"\\rEpisode: {episode + 1}, Steps: {step + 1}, eps: {epsilon:.3f}\",\n",
    "          end=\"\")\n",
    "    rewards.append(step)\n",
    "    if step >= best_score:\n",
    "        best_weights = model.get_weights()\n",
    "        best_score = step\n",
    "\n",
    "    if episode > 50:\n",
    "        training_step(batch_size)\n",
    "\n",
    "model.set_weights(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(EPSILON, EPSILON_DECAY):\n",
    "    state = env.reset()[0]\n",
    "    state_position = np.digitize(state[0], position)\n",
    "    state_velocity = np.digitize(state[1], velocity)\n",
    "\n",
    "    goal = False\n",
    "\n",
    "    rewards = 0\n",
    "\n",
    "    while not goal and rewards > -1000:\n",
    "        action = select_action(state)\n",
    "        next_state, reward, goal, _, _ = env.step(action)\n",
    "        next_state_position = np.digitize(next_state[0], position)\n",
    "        next_state_velocity = np.digitize(next_state[1], velocity)\n",
    "        max_q_value_next_state = np.max(q_values[next_state_position][next_state_velocity])\n",
    "        q_values[state_position][state_velocity][action] += LEARNING_RATE * (reward + DISCOUNT_FACTOR * \n",
    "                                max_q_value_next_state - q_values[state_position][state_velocity][action])\n",
    "        state_position = next_state_position\n",
    "        state_velocity = next_state_velocity\n",
    "\n",
    "        rewards += reward\n",
    "\n",
    "    rewards_per_episode.append(rewards)\n",
    "    NEW_EPSILON = max(EPSILON - EPSILON_DECAY, 0)\n",
    "    return NEW_EPSILON\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for episode in range(NUM_EPISODES):\n",
    "#     EPSILON = train(EPSILON, EPSILON_DECAY)\n",
    "\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1951ba7fbd0>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_rewards = np.zeros(NUM_EPISODES)\n",
    "for t in range(NUM_EPISODES):\n",
    "    mean_rewards[t] = np.mean(rewards_per_episode[max(0, t-100):(t+1)])\n",
    "plt.plot(mean_rewards)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
